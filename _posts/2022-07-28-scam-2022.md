---
layout: post
title: "\"An Empirical Study of Code Smells in Transformer-based Code Generation Techniques\" accepted at SCAM 2022"
short_title: "Paper accepted at SCAM 2022"
date: 2022-07-28 19:00:00 -0400
categories: paper research
author: "Mohammed Latif Siddiq"
img: Methodology_Scam_2022.png
thumb: SCAM_logo.png
tags: scam22
excerpt: "Our paper, \"An Empirical Study of Code Smells in Transformer-based Code Generation Techniques\", got accepted for the 22nd IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2022) in the research track."
---

Our paper, **"An Empirical Study of Code Smells in Transformer-based Code Generation Techniques"**, got accepted for the 22nd IEEE International Working Conference on Source Code Analysis and Manipulation (SCAM 2022) in the research track. 

We carry out a thorough empirical analysis of code smells in Python transformer-based code generation models' training sets and look at how these bad patterns get up in the output. In order to carry out this study, we obtained three open-source datasets (CodeXGlue, APPS, and Code Clippy) that are frequently used to train Python code generation techniques and checked to see how much code smells were present in them. We also looked into the possibility of code smells in the code produced by transformer-based models. For this experiment, we calculated the code smells in the outputs produced by the open-source and closed-source code generating tools GPT-Code-Clippy and GitHub Copilot, respectively. 

This paper makes three contributions:
- a comprehensive empirical analysis of code smell occurrence in the dataset and the results of transformer-based Python code generation methods
- an examination of the potential differences between transformer-based open-source and closed-source methodologies
- a discussion of the implications of the results for researchers and practitioners.

Pre-print: [SCAM 2022](https://s2e-lab.github.io/preprints/scam22-preprint.pdf)
Source Code: [GitHub](https://github.com/s2e-lab/Code-Smell-Code-Generation)